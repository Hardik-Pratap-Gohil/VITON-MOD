# VITON-MOD: Interactive Cloth Editor for VITON-HD## VITON-HD



An interactive web application built on top of [VITON-HD](https://arxiv.org/abs/2103.16874) (Choi et al., CVPR 2021) that enables realistic cloth editing through colors, patterns, logos, and textures **without retraining any models**.We worked on extending [VITON-HD](https://arxiv.org/abs/2103.16874) by Choi et. al. CVPR 2021.



## âœ¨ Features## Instructions To Run Project



- **ğŸ¨ Color Editing**```bash

  - 6 preset palettes (Vibrant, Pastel, Earth, Monochrome, Warm, Cool)git clone ...

  - Custom HSV adjustments (Hue, Saturation, Brightness)```

  

- **ğŸ­ Pattern Overlay**## Repository Structure

  - Procedurally generated patterns (Stripes, Polkadots, Checkerboard)```plaintext

  - Customizable colors, sizes, and blend modes|-- README.md

  - Preserves original cloth lighting and shadows```

  

- **ğŸ·ï¸ Logo Placement**## Citation

  - Add text logos with custom text, position, size, and color```cite

  - Automatically warps with the cloth for realistic appearance@inproceedings{choi2021viton,

    title={VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization},

- **ğŸ§µ Fabric Textures**  author={Choi, Seunghwan and Park, Sunghyun and Lee, Minsoo and Choo, Jaegul},

  - Simulate different materials (Canvas, Denim, Silk, Linen)  booktitle={Proc. of the IEEE conference on computer vision and pattern recognition (CVPR)},

  - Subtle texture enhancements without artifacts  year={2021}

}

## ğŸš€ Quick Start```



### Prerequisites## References



- Python 3.8+- [Author's github](https://github.com/shadow2496/VITON-HD)
- 16GB RAM (CPU-only, no GPU required)
- conda (recommended for environment management)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Hardik-Pratap-Gohil/VITON-MOD.git
cd VITON-MOD
```

2. **Create conda environment**
```bash
conda create -n viton-env python=3.8
conda activate viton-env
```

3. **Install dependencies**
```bash
pip install torch==2.4.1 torchvision==0.20.0 --index-url https://download.pytorch.org/whl/cpu
pip install opencv-python==4.12.0.90 pillow numpy streamlit
pip install torchgeometry
```

4. **Download pretrained models**

Place the following checkpoints in `./checkpoints/`:
- `seg_final.pth` (132 MB) - Segmentation model
- `gmm_final.pth` (73 MB) - Geometric Matching Module
- `alias_final.pth` (384 MB) - ALIAS Generator

5. **Prepare dataset** (optional - sample dataset included)

Place test images in `./datasets/test/`:
```
datasets/test/
â”œâ”€â”€ image/              # Person images
â”œâ”€â”€ cloth/              # Cloth images  
â”œâ”€â”€ cloth-mask/         # Cloth masks
â”œâ”€â”€ image-parse/        # Segmentation maps
â”œâ”€â”€ openpose-img/       # Pose visualizations
â””â”€â”€ openpose-json/      # Pose keypoints
```

### Running the App

**Start the Streamlit web application:**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ“– Usage

1. **Select Person & Cloth**: Choose from dropdown menus in the sidebar
2. **Choose Resolution**: Preview (fast) or HD (high quality)
3. **Edit Cloth**: Use tabs to apply colors, patterns, logos, or textures
4. **Generate**: Click "Generate Try-On" to see results
5. **Download**: Save the final image using the download button

## ğŸ§ª Testing

Run comprehensive tests to verify all editing capabilities:

```bash
# Test realistic editing features (colors, patterns, logos, textures)
python realistic_test.py

# Test logo placement variations
python logo_test.py

# Run original VITON-HD inference
python test.py
```

Results are saved in `./results/` with organized subdirectories.

## ğŸ“ Repository Structure

```
VITON-MOD/
â”œâ”€â”€ app.py                      # Streamlit web application
â”œâ”€â”€ cloth_editor.py             # Editing tools (colors, patterns, logos, textures)
â”œâ”€â”€ inference_pipeline.py       # VITON-HD pipeline wrapper
â”œâ”€â”€ preprocessing.py            # Data loading utilities
â”œâ”€â”€ networks.py                 # Neural network architectures
â”œâ”€â”€ utils.py                    # Helper functions
â”œâ”€â”€ datasets.py                 # Dataset class (original VITON-HD)
â”‚
â”œâ”€â”€ realistic_test.py           # Comprehensive editing tests
â”œâ”€â”€ logo_test.py                # Logo placement tests
â”œâ”€â”€ comprehensive_test.py       # General feature tests
â”œâ”€â”€ test.py                     # Original VITON-HD inference
â”‚
â”œâ”€â”€ checkpoints/                # Pretrained model weights
â”‚   â”œâ”€â”€ seg_final.pth
â”‚   â”œâ”€â”€ gmm_final.pth
â”‚   â””â”€â”€ alias_final.pth
â”‚
â”œâ”€â”€ datasets/                   # Test data
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ image/              # 6 person images
â”‚       â”œâ”€â”€ cloth/              # 12 cloth items
â”‚       â”œâ”€â”€ cloth-mask/
â”‚       â”œâ”€â”€ image-parse/
â”‚       â”œâ”€â”€ openpose-img/
â”‚       â””â”€â”€ openpose-json/
â”‚
â”œâ”€â”€ assets/                     # Optional custom content
â”‚   â”œâ”€â”€ logos/                  # Custom logo images (PNG)
â”‚   â”œâ”€â”€ patterns/               # Custom pattern tiles
â”‚   â””â”€â”€ accessories/            # Reference images
â”‚
â””â”€â”€ results/                    # Generated outputs
    â”œâ”€â”€ realistic_test/
    â”œâ”€â”€ logo_test/
    â””â”€â”€ comprehensive_test/
```

## ğŸ¯ Design Philosophy

### Why Edit the Source Cloth?

Unlike traditional approaches that modify intermediate pipeline outputs (which causes artifacts), VITON-MOD applies all edits to the **source cloth image** before it enters the VITON-HD pipeline. This ensures:

âœ… **No artifacts** - VITON-HD's GMM naturally warps the edited cloth  
âœ… **Preserved alignment** - Cloth and mask remain perfectly synchronized  
âœ… **Realistic results** - Original lighting, shadows, and folds are maintained  

### What Doesn't Work (and why we don't do it)

âŒ **Fit adjustments via mask morphology** - Breaks cloth-mask alignment, causes artifacts  
âŒ **Sleeve length modifications** - Creates visible distortions  
âŒ **Post-processing on warped outputs** - Disrupts carefully learned features  

## ğŸ”§ Technical Details

- **Framework**: Built on VITON-HD (CVPR 2021) pretrained models
- **Inference**: CPU-only, ~60-90 seconds per 1024Ã—768 image
- **Editing**: Pre-processing approach (edit source â†’ warp naturally)
- **UI**: Streamlit for interactive web interface
- **No Training Required**: Pure post-processing and pre-processing techniques

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional pattern generators (floral, camouflage, etc.)
- Custom logo image support (currently text-only)
- Accessory rendering using pose keypoints
- Region-specific color editing (different colors for sleeves vs body)

## ğŸ“„ License

See [LICENSE](LICENSE) file for details.

## ğŸ“š Citation

If you use this work, please cite the original VITON-HD paper:

```bibtex
@inproceedings{choi2021viton,
  title={VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization},
  author={Choi, Seunghwan and Park, Sunghyun and Lee, Minsoo and Choo, Jaegul},
  booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}
```

## ğŸ”— References

- [VITON-HD Paper](https://arxiv.org/abs/2103.16874)
- [Original VITON-HD Implementation](https://github.com/shadow2496/VITON-HD)
- [VITON-MOD Repository](https://github.com/Hardik-Pratap-Gohil/VITON-MOD)

## ğŸ™ Acknowledgments

Built upon the excellent work of Choi et al. in VITON-HD. This project extends their framework with interactive editing capabilities for educational and research purposes.
