# VITON-MOD: Interactive Cloth Editor for VITON-HD

An interactive web application built on top of [VITON-HD](https://arxiv.org/abs/2103.16874) (Choi et al., CVPR 2021) that enables realistic cloth editing through colors, patterns, logos, and textures **without retraining any models**. 

## âœ¨ Features

- **ğŸ¨ Color Editing**

  - 6 preset palettes (Vibrant, Pastel, Earth, Monochrome, Warm, Cool)

  - Custom HSV adjustments (Hue, Saturation, Brightness)

- **ğŸ­ Pattern Overlay**

  - Procedurally generated patterns (Stripes, Polkadots, Checkerboard)

  - Customizable colors, sizes, and blend modes

  - Preserves original cloth lighting and shadows

- **ğŸ·ï¸ Logo Placement**

  - Add text logos with custom text, position, size, and color

  - Automatically warps with the cloth for realistic appearance

- **ğŸ§µ Fabric Textures**

  - Simulate different materials (Canvas, Denim, Silk, Linen)

  - Subtle texture enhancements without artifacts
  - 

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- 16GB RAM (CPU-only, no GPU required)
- conda (recommended for environment management)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Hardik-Pratap-Gohil/VITON-MOD.git
cd VITON-MOD
```

2. **Create conda environment**
```bash
conda create -n viton-env python=3.8
conda activate viton-env
```

3. **Install dependencies**
```bash
pip install torch==2.4.1 torchvision==0.20.0 --index-url https://download.pytorch.org/whl/cpu
pip install opencv-python==4.12.0.90 pillow numpy streamlit
pip install torchgeometry
```

4. **Download pretrained models**

Place the following checkpoints in `./checkpoints/`:
- `seg_final.pth` (132 MB) - Segmentation model
- `gmm_final.pth` (73 MB) - Geometric Matching Module
- `alias_final.pth` (384 MB) - ALIAS Generator

5. **Prepare dataset** (optional - sample dataset included)

Place test images in `./datasets/test/`:
```
datasets/test/
â”œâ”€â”€ image/              # Person images
â”œâ”€â”€ cloth/              # Cloth images  
â”œâ”€â”€ cloth-mask/         # Cloth masks
â”œâ”€â”€ image-parse/        # Segmentation maps
â”œâ”€â”€ openpose-img/       # Pose visualizations
â””â”€â”€ openpose-json/      # Pose keypoints
```

### Running the App

**Start the Streamlit web application:**
```bash
# Using the convenience script
./scripts/run_app.sh

# Or directly
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ“– Usage

1. **Select Person & Cloth**: Choose from dropdown menus in the sidebar
2. **Choose Resolution**: Preview (fast) or HD (high quality)
3. **Edit Cloth**: Use tabs to apply colors, patterns, logos, or textures
4. **Generate**: Click "Generate Try-On" to see results
5. **Download**: Save the final image using the download button

## ğŸ§ª Testing

Run comprehensive tests to verify all editing capabilities:

```bash
# Using convenience script
./scripts/run_tests.sh

# Or run tests individually
python tests/realistic_test.py  # Test colors, patterns, logos, textures (24 images)
python tests/logo_test.py       # Test logo placement variations (25 images)
python tests/test.py            # Run original VITON-HD inference
```

Results are saved in `./results/` with organized subdirectories.

## ğŸ“ Repository Structure

```
VITON-MOD/
â”œâ”€â”€ app.py                      # Streamlit web application
â”‚
â”œâ”€â”€ src/                        # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cloth_editor.py         # Editing tools (colors, patterns, logos, textures)
â”‚   â”œâ”€â”€ inference_pipeline.py   # VITON-HD pipeline wrapper
â”‚   â”œâ”€â”€ preprocessing.py        # Data loading utilities
â”‚   â”œâ”€â”€ networks.py             # Neural network architectures
â”‚   â”œâ”€â”€ utils.py                # Helper functions
â”‚   â””â”€â”€ datasets.py             # Dataset class (original VITON-HD)
â”‚
â”œâ”€â”€ tests/                      # Test scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ realistic_test.py       # Comprehensive editing tests (24 images)
â”‚   â”œâ”€â”€ logo_test.py            # Logo placement tests (25 images)
â”‚   â”œâ”€â”€ comprehensive_test.py   # General feature tests
â”‚   â””â”€â”€ test.py                 # Original VITON-HD inference
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ run_app.sh              # Launch Streamlit app
â”‚   â””â”€â”€ run_tests.sh            # Run all tests
â”‚
â”œâ”€â”€ checkpoints/                # Pretrained model weights
â”‚   â”œâ”€â”€ seg_final.pth           # Segmentation model (132 MB)
â”‚   â”œâ”€â”€ gmm_final.pth           # Geometric Matching Module (73 MB)
â”‚   â””â”€â”€ alias_final.pth         # ALIAS Generator (384 MB)
â”‚
â”œâ”€â”€ datasets/                   # Test data
â”‚   â”œâ”€â”€ test_pairs.txt
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ image/              # 6 person images
â”‚       â”œâ”€â”€ cloth/              # 12 cloth items
â”‚       â”œâ”€â”€ cloth-mask/         # Cloth segmentation masks
â”‚       â”œâ”€â”€ image-parse/        # Person segmentation maps
â”‚       â”œâ”€â”€ openpose-img/       # Pose visualizations
â”‚       â””â”€â”€ openpose-json/      # Pose keypoints (JSON)
â”‚
â”œâ”€â”€ assets/                     # Optional custom content
â”‚   â”œâ”€â”€ logos/                  # Custom logo images (PNG)
â”‚   â”œâ”€â”€ patterns/               # Custom pattern tiles
â”‚   â””â”€â”€ accessories/            # Reference images
â”‚
â””â”€â”€ results/                    # Generated outputs
    â”œâ”€â”€ realistic_test/         # Realistic editing test results
    â”œâ”€â”€ logo_test/              # Logo placement test results
    â””â”€â”€ comprehensive_test/     # General test results
```

## ğŸ¯ Design

### Why Edit the Source Cloth?

Unlike traditional approaches that modify intermediate pipeline outputs (which causes artifacts), VITON-MOD applies all edits to the **source cloth image** before it enters the VITON-HD pipeline. This ensures:

âœ… **No artifacts** - VITON-HD's GMM naturally warps the edited cloth  
âœ… **Preserved alignment** - Cloth and mask remain perfectly synchronized  
âœ… **Realistic results** - Original lighting, shadows, and folds are maintained  

### What Doesn't Work (and why we don't do it)

âŒ **Fit adjustments via mask morphology** - Breaks cloth-mask alignment, causes artifacts  
âŒ **Sleeve length modifications** - Creates visible distortions  
âŒ **Post-processing on warped outputs** - Disrupts carefully learned features  

## ğŸ”§ Technical Details

- **Framework**: Built on VITON-HD (CVPR 2021) pretrained models
- **Inference**: CPU-only, ~60-90 seconds per 1024Ã—768 image
- **Editing**: Pre-processing approach (edit source â†’ warp naturally)
- **UI**: Streamlit for interactive web interface
- **No Training Required**: Pure post-processing and pre-processing techniques

## ğŸ“š Citation

```bibtex
@inproceedings{choi2021viton,
  title={VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization},
  author={Choi, Seunghwan and Park, Sunghyun and Lee, Minsoo and Choo, Jaegul},
  booktitle={Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}
```

## ğŸ”— References

- [VITON-HD Paper](https://arxiv.org/abs/2103.16874)
- [Original VITON-HD Implementation](https://github.com/shadow2496/VITON-HD)
- [VITON-MOD Repository](https://github.com/Hardik-Pratap-Gohil/VITON-MOD)

## ğŸ™ Acknowledgments

Built upon the excellent work of Choi et al. in VITON-HD. This project extends their framework with interactive editing capabilities for educational and research purposes.
